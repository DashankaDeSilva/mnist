{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preproc(x):\n",
    "    x = x*2 - 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Solver:\n",
    "    def __init__(self, sess, model):\n",
    "        self.model = model\n",
    "        self.sess = sess\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        feed = {\n",
    "            self.model.X: X,\n",
    "            self.model.y: y,\n",
    "            self.model.training: True\n",
    "        }\n",
    "        train_op = self.model.train_op\n",
    "        loss = self.model.loss\n",
    "        \n",
    "        return self.sess.run([train_op, loss], feed_dict=feed)\n",
    "    \n",
    "    def evaluate(self, X, y, batch_size=None):\n",
    "        if batch_size:\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            total_loss = 0\n",
    "            total_acc = 0\n",
    "            \n",
    "            for i in range(0, N, batch_size):\n",
    "                X_batch = X[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "                \n",
    "                feed = {\n",
    "                    self.model.X: X_batch,\n",
    "                    self.model.y: y_batch,\n",
    "                    self.model.training: False\n",
    "                }\n",
    "                \n",
    "                loss = self.model.loss\n",
    "                accuracy = self.model.accuracy\n",
    "                \n",
    "                step_loss, step_acc = self.sess.run([loss, accuracy], feed_dict=feed)\n",
    "                \n",
    "                total_loss += step_loss * X_batch.shape[0]\n",
    "                total_acc += step_acc * X_batch.shape[0]\n",
    "            \n",
    "            total_loss /= N\n",
    "            total_acc /= N\n",
    "            \n",
    "            return total_loss, total_acc\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            feed = {\n",
    "                self.model.X: X,\n",
    "                self.model.y: y,\n",
    "                self.model.training: False\n",
    "            }\n",
    "            \n",
    "            loss = self.model.loss            \n",
    "            accuracy = self.model.accuracy\n",
    "\n",
    "            return self.sess.run([loss, accuracy], feed_dict=feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, name, lr=0.001):\n",
    "        with tf.variable_scope(name):\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "            self.y = tf.placeholder(tf.float32, [None, 10], name='y')\n",
    "            self.training = tf.placeholder(tf.bool, name='training')\n",
    "            \n",
    "            x = preproc(self.X)\n",
    "            x_img = tf.reshape(x, [-1, 28, 28, 1])\n",
    "            \n",
    "#             h1_conv = tf.layers.conv2d(x_img, 64, [5,5], strides=2, padding='SAME', use_bias=False)\n",
    "#             h1_bn = tf.layers.batch_normalization(h1_conv, training=self.training)\n",
    "#             h1 = tf.nn.relu(h1_bn) # 14x14\n",
    "#             h2_conv = tf.layers.conv2d(h1, 128, [5,5], strides=2, padding='SAME', use_bias=False)\n",
    "#             h2_bn = tf.layers.batch_normalization(h2_conv, training=self.training)\n",
    "#             h2 = tf.nn.relu(h2_bn) # 7x7\n",
    "#             h3_conv = tf.layers.conv2d(h2, 256, [5,5], strides=2, padding='SAME', use_bias=False)\n",
    "#             h3_bn = tf.layers.batch_normalization(h3_conv, training=self.training)\n",
    "#             h3 = tf.nn.relu(h3_bn) # 4x4\n",
    "            \n",
    "            # hidden layers\n",
    "            net = x_img\n",
    "            n_filters = 64\n",
    "            for i in range(3):\n",
    "                net = tf.layers.conv2d(net, n_filters, [3,3], strides=1, kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                       padding='SAME', use_bias=False)\n",
    "                net = tf.layers.batch_normalization(net, training=self.training)\n",
    "                net = tf.nn.relu(net)\n",
    "                net = tf.layers.dropout(net, rate=0.3, training=self.training)\n",
    "                \n",
    "                net = tf.layers.conv2d(net, n_filters, [5,5], strides=2, kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
    "                                       padding='SAME', use_bias=False)\n",
    "#                 net = tf.layers.max_pooling2d(net, pool_size=[2,2], strides=2)\n",
    "                net = tf.layers.batch_normalization(net, training=self.training)\n",
    "                net = tf.nn.relu(net)\n",
    "                net = tf.layers.dropout(net, rate=0.3, training=self.training)\n",
    "                n_filters *= 2\n",
    "            \n",
    "            # x: [28, 28, 1]\n",
    "            # h1: [14, 14, 64]\n",
    "            # h2: [7, 7, 128]\n",
    "            # h3: [4, 4, 256]\n",
    "            # 4096 -> 1024 -> 10\n",
    "            \n",
    "            net = tf.contrib.layers.flatten(net)\n",
    "#             net = tf.layers.dense(net, 1024, activation=tf.nn.relu)\n",
    "#             net = tf.layers.dropout(net, rate=0.5, training=self.training)\n",
    "            logits = tf.layers.dense(net, 10, weights_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=self.y))\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=name)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                self.train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.loss)    \n",
    "            \n",
    "            self.pred = tf.argmax(logits, axis=1)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(tf.equal(self.pred, tf.argmax(self.y, axis=1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "basic_cnn = Model('basic_cnn', lr=0.001)\n",
    "solver = Solver(sess, basic_cnn)\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/60] train: 0.0675, 98.113% / valid: 0.0682, 98.18% / test: 0.0521, 98.47%\n",
      "[02/60] train: 0.0673, 98.100% / valid: 0.0734, 98.20% / test: 0.0521, 98.32%\n",
      "[03/60] train: 0.0384, 98.885% / valid: 0.0515, 98.52% / test: 0.0417, 98.78%\n",
      "[04/60] train: 0.0294, 99.127% / valid: 0.0396, 98.92% / test: 0.0345, 99.01%\n",
      "[05/60] train: 0.0348, 98.911% / valid: 0.0469, 98.74% / test: 0.0451, 98.69%\n",
      "[06/60] train: 0.0149, 99.527% / valid: 0.0262, 99.30% / test: 0.0232, 99.32%\n",
      "[07/60] train: 0.0142, 99.571% / valid: 0.0266, 99.20% / test: 0.0234, 99.24%\n",
      "[08/60] train: 0.0165, 99.495% / valid: 0.0349, 98.98% / test: 0.0247, 99.31%\n",
      "[09/60] train: 0.0119, 99.627% / valid: 0.0303, 99.24% / test: 0.0242, 99.23%\n",
      "[10/60] train: 0.0116, 99.653% / valid: 0.0309, 99.14% / test: 0.0209, 99.37%\n",
      "[11/60] train: 0.0061, 99.820% / valid: 0.0223, 99.36% / test: 0.0185, 99.45%\n",
      "[12/60] train: 0.0139, 99.516% / valid: 0.0382, 99.04% / test: 0.0283, 99.18%\n",
      "[13/60] train: 0.0245, 99.247% / valid: 0.0511, 98.70% / test: 0.0425, 98.84%\n",
      "[14/60] train: 0.0040, 99.871% / valid: 0.0207, 99.40% / test: 0.0172, 99.47%\n",
      "[15/60] train: 0.0051, 99.838% / valid: 0.0226, 99.34% / test: 0.0207, 99.45%\n",
      "[16/60] train: 0.0051, 99.838% / valid: 0.0256, 99.34% / test: 0.0229, 99.45%\n",
      "[17/60] train: 0.0046, 99.858% / valid: 0.0237, 99.42% / test: 0.0223, 99.38%\n",
      "[18/60] train: 0.0061, 99.822% / valid: 0.0404, 99.10% / test: 0.0275, 99.36%\n",
      "[19/60] train: 0.0048, 99.835% / valid: 0.0334, 99.30% / test: 0.0277, 99.38%\n",
      "[20/60] train: 0.0026, 99.909% / valid: 0.0263, 99.44% / test: 0.0217, 99.41%\n",
      "[21/60] train: 0.0036, 99.891% / valid: 0.0316, 99.22% / test: 0.0247, 99.43%\n",
      "[22/60] train: 0.0027, 99.911% / valid: 0.0285, 99.56% / test: 0.0251, 99.40%\n",
      "[23/60] train: 0.0015, 99.960% / valid: 0.0231, 99.50% / test: 0.0210, 99.53%\n",
      "[24/60] train: 0.0033, 99.891% / valid: 0.0327, 99.40% / test: 0.0242, 99.54%\n",
      "[25/60] train: 0.0018, 99.949% / valid: 0.0227, 99.62% / test: 0.0226, 99.53%\n",
      "[26/60] train: 0.0013, 99.955% / valid: 0.0270, 99.44% / test: 0.0228, 99.48%\n",
      "[27/60] train: 0.0012, 99.965% / valid: 0.0224, 99.54% / test: 0.0214, 99.46%\n",
      "[28/60] train: 0.0014, 99.962% / valid: 0.0283, 99.34% / test: 0.0251, 99.47%\n",
      "[29/60] train: 0.0012, 99.958% / valid: 0.0281, 99.40% / test: 0.0226, 99.51%\n",
      "[30/60] train: 0.0015, 99.947% / valid: 0.0319, 99.36% / test: 0.0246, 99.51%\n",
      "[31/60] train: 0.0034, 99.878% / valid: 0.0336, 99.28% / test: 0.0254, 99.45%\n",
      "[32/60] train: 0.0006, 99.978% / valid: 0.0296, 99.46% / test: 0.0231, 99.50%\n",
      "[33/60] train: 0.0007, 99.973% / valid: 0.0244, 99.46% / test: 0.0199, 99.54%\n",
      "[34/60] train: 0.0009, 99.967% / valid: 0.0285, 99.56% / test: 0.0221, 99.58%\n",
      "[35/60] train: 0.0007, 99.982% / valid: 0.0275, 99.42% / test: 0.0269, 99.55%\n",
      "[36/60] train: 0.0039, 99.900% / valid: 0.0389, 99.30% / test: 0.0285, 99.49%\n",
      "[37/60] train: 0.0005, 99.985% / valid: 0.0292, 99.56% / test: 0.0263, 99.41%\n",
      "[38/60] train: 0.0010, 99.973% / valid: 0.0241, 99.52% / test: 0.0234, 99.45%\n",
      "[39/60] train: 0.0008, 99.980% / valid: 0.0268, 99.58% / test: 0.0259, 99.42%\n",
      "[40/60] train: 0.0006, 99.984% / valid: 0.0290, 99.42% / test: 0.0255, 99.40%\n",
      "[41/60] train: 0.0017, 99.955% / valid: 0.0324, 99.36% / test: 0.0264, 99.47%\n",
      "[42/60] train: 0.0003, 99.989% / valid: 0.0224, 99.44% / test: 0.0220, 99.52%\n",
      "[43/60] train: 0.0009, 99.967% / valid: 0.0274, 99.58% / test: 0.0190, 99.50%\n",
      "[44/60] train: 0.0002, 99.995% / valid: 0.0272, 99.54% / test: 0.0238, 99.53%\n",
      "[45/60] train: 0.0009, 99.965% / valid: 0.0286, 99.32% / test: 0.0271, 99.43%\n",
      "[46/60] train: 0.0013, 99.955% / valid: 0.0294, 99.42% / test: 0.0336, 99.45%\n",
      "[47/60] train: 0.0003, 99.987% / valid: 0.0285, 99.50% / test: 0.0253, 99.51%\n",
      "[48/60] train: 0.0008, 99.971% / valid: 0.0338, 99.46% / test: 0.0353, 99.43%\n",
      "[49/60] train: 0.0011, 99.969% / valid: 0.0293, 99.32% / test: 0.0279, 99.47%\n",
      "[50/60] train: 0.0003, 99.991% / valid: 0.0284, 99.44% / test: 0.0247, 99.45%\n",
      "[51/60] train: 0.0002, 99.991% / valid: 0.0271, 99.54% / test: 0.0284, 99.49%\n",
      "[52/60] train: 0.0005, 99.984% / valid: 0.0272, 99.48% / test: 0.0266, 99.55%\n",
      "[53/60] train: 0.0004, 99.989% / valid: 0.0292, 99.52% / test: 0.0263, 99.60%\n",
      "[54/60] train: 0.0001, 99.998% / valid: 0.0287, 99.58% / test: 0.0225, 99.56%\n",
      "[55/60] train: 0.0007, 99.969% / valid: 0.0322, 99.38% / test: 0.0275, 99.48%\n",
      "[56/60] train: 0.0002, 99.991% / valid: 0.0265, 99.52% / test: 0.0269, 99.49%\n",
      "[57/60] train: 0.0009, 99.965% / valid: 0.0264, 99.50% / test: 0.0265, 99.51%\n",
      "[58/60] train: 0.0003, 99.991% / valid: 0.0284, 99.54% / test: 0.0267, 99.46%\n",
      "[59/60] train: 0.0004, 99.984% / valid: 0.0252, 99.40% / test: 0.0270, 99.46%\n",
      "[60/60] train: 0.0002, 99.996% / valid: 0.0327, 99.58% / test: 0.0248, 99.47%\n",
      "[train max] [54/60] train: 0.0001, 99.998% / valid: 0.0287, 99.58% / test: 0.0225, 99.56%\n",
      "[valid max] [25/60] train: 0.0018, 99.949% / valid: 0.0227, 99.62% / test: 0.0226, 99.53%\n",
      "[ test max] [53/60] train: 0.0004, 99.989% / valid: 0.0292, 99.52% / test: 0.0263, 99.60%\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 50\n",
    "epoch_n = 60\n",
    "N = mnist.train.num_examples\n",
    "\n",
    "max_train_acc = 0\n",
    "max_valid_acc = 0\n",
    "max_test_acc = 0\n",
    "\n",
    "for epoch in range(epoch_n):\n",
    "    for _ in range(N // batch_size):\n",
    "        batches = mnist.train.next_batch(batch_size)\n",
    "        _, train_loss = solver.train(batches[0], batches[1])\n",
    "#         sess.run(solver, {X: batches[0], y: batches[1]})\n",
    "    \n",
    "    train_loss, train_acc = solver.evaluate(mnist.train.images, mnist.train.labels, 1000)\n",
    "    valid_loss, valid_acc = solver.evaluate(mnist.validation.images, mnist.validation.labels, 1000)\n",
    "    test_loss, test_acc = solver.evaluate(mnist.test.images, mnist.test.labels, 1000)\n",
    "    line = \"[{:0>2d}/{}] train: {:.4f}, {:.3%} / valid: {:.4f}, {:.2%} / test: {:.4f}, {:.2%}\". \\\n",
    "    format(epoch+1, epoch_n, train_loss, train_acc, valid_loss, valid_acc, test_loss, test_acc)\n",
    "    print(line)\n",
    "    \n",
    "    if train_acc > max_train_acc:\n",
    "        max_train_acc = train_acc\n",
    "        train_line = line\n",
    "    if valid_acc > max_valid_acc:\n",
    "        max_valid_acc = valid_acc\n",
    "        valid_line = line\n",
    "    if test_acc > max_test_acc:\n",
    "        max_test_acc = test_acc\n",
    "        test_line = line\n",
    "    \n",
    "\n",
    "print(\"[train max] {}\".format(train_line))\n",
    "print(\"[valid max] {}\".format(valid_line))\n",
    "print(\"[ test max] {}\".format(test_line))\n",
    "# print(\"last maximum train acc: {:.2%}\".format(max_train_acc))\n",
    "# print(\"last maximum valid acc: {:.2%}\".format(max_valid_acc))\n",
    "# print(\"last maximum test acc: {:.2%}\".format(max_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* basic-without preproc(zero-centered mean): 98.60%\n",
    "* basic: 98.95%\n",
    "* BN: 98.68%\n",
    "    * BN-0.01: 94%\n",
    "    * BN-0.05: 98.29%\n",
    "\n",
    "\n",
    "* 2-strided models\n",
    "    * BN: 99.26%\n",
    "        * bias: 99.15%\n",
    "    * No-BN, No-bias: 99.10%\n",
    "    * No-BN: 99.26%\n",
    "        * added 1 more 1024 dense layer: 99.00%\n",
    "        * normalized input: 99.15%\n",
    "* [(3,3),1] + [(5,5),2] model + BN\n",
    "    * 2-FC + dropout: 99.39%, 99.46%\n",
    "    * 1-FC: 99.52%, 99.49%\n",
    "        * conv dropout 0.5: 99.53%\n",
    "        * conv dropout 0.2: 99.45?\n",
    "        * conv dropout 0.7: 99.11%, 99.35% (batch size 50)\n",
    "        * conv dropout 0.3 + batch size 50 + epoch 30: 99.55%\n",
    "* [(3,3),1] + [(3,3),2] model + BN\n",
    "    * 1-FC\n",
    "        * conv dropout 0.1: 99.41%\n",
    "* max pooling 99.35%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
